---
layout: notes
title: Notes
---
{% include title.html name="2019-10-08" %}

While biking along the Grand Allegheny Passage this summer (h/t MC and
MP for making this trip happen), I got thinking through a [_complexity
science_][complexity-note] lens about the quality of the experience, in
relation to the forest around me. It got me thinking about futures, and
the possibility field of the present moment.

We were rapidly passing through this incredibly complex and dynamic environment.
We were part of a collective (humanity) that ostensibly recognizes its
dependence on that natural environment for its own flourishing, but perhaps
doesn't recognize the scale of that dependance. For the most part,
humanity ignores it and just lets nature be, and that generally works
out when we don't have a specific need to consume/destroy it.

So anyhow, we're cycling through this beautiful natural system, and I'm imagining how my
presence must feel or look to the participants of that place. The
plants, the bugs, the birds, the squirrels. I am this thing that zooms
through their sensory domain, mostly without stopping and participating
in the things that have such primacy to them. In the language of
complexity science, I am a _volatile structure_ and I flit through
relatively unceremoniously, on my way to concerns they cannot understand or
comprehend.

But it's perhaps a little more complicated than a cold alien
visitation of sorts. Because they maybe don't realize it, but there's something
about them that brings me peace. Natural systems rejuvenate us all. If
only due to some evolutionary baggage, which you might think of as
genetic nostalgia.  We've perhaps preserved that nostalgia in our bones,
because this reverance is important to our not "innovating" the lower
levels completely out of existence. Or from another perspective, maybe
our capacity to be endeared by the natural, to be nostalgic for these
places we live in less and less, is the reason we're still here. It's
the reason we haven't totally destroyed this place yet. To frame it
otherwise might be [survivorship bias][survivorship], plain and simple.

   [survivorship]: https://en.wikipedia.org/wiki/Survivorship_bias

And thinking on this, I wonder about the next phase of things...
1. Will the artificial forms of life to come, will they feel similarly of the domain of flesh, biology and human society?
1. Will they do the equivalent of cycling through the rejuvenating forest of human minds, while taking pause from their unknowable affairs?
1. Are we guaranteed that they will feel this way for all of us? Will we be their bugs or their squirrel? Will we be easy for them to protect?
1. And if not, how might we better guarantee that they _do have_ the sort of development that creates this interdependance in their formative years?
  Can we _engineer_ -- or no, rather -- can we _cultivate_ that reverence?
1. Can we tie their fates to ours in a way that ensures we're eventually endeared (if not also experienced as quaint and simple)?
1. Will they connect more with those of us that share aspects of their character, like how [dogs trigger neural activity of parent-child pair-bonding][pet-pair-bonding]?
1. And if there are human characteristics we hope to share with them, how might we nudge toward that path, if at all possible?


   [pet-pair-bonding]: https://www.sciencedaily.com/releases/2014/10/141003214344.htm

{% include title.html name="2019-10-07" %}

_**Gratitude:** Thanks to my brother CC for introducing me to the work
of adrienne marie brown, even though I got distracted from reading it
for a year or two. And thanks so much to CS and LB for being great
friends and re-energizing me to explore the works of both AMB and
Octavia Butler._

In the past year, I've read two books that have offered some new angles
I'm still reflecting on. The books feels a little bit like secret
sisters. In some ways, they are totally not about the same things, and
each author might even be offended to be put in the same basket. But it
feels like they're each getting at some common concepts, but from
different perspectives.

The first book is _Emergent Strategy_ by adrienne marie brown. The book is
ostensibly about community organizing and how to build networks "an inch
wide and a mile deep". The book is filled with personal anecdotes and
truly puts relationships at the centre of the message. AMB goes to great
effort early in the book to clarify that she doesn't understand lots of
the science that she's leaning on -- that she's intuiting her way around
the general concepts. But as a science-informed person myself
(biochemistry background), I am floored by how well she seems to put a
finger down on so many subtle truths.

The second book is _A Brief History of Everything_ by Ken Wilber. The
book tries to do what it says on the tin. Speaking of which, Wilbur
[puts his face on the cover of most versions of the book][2019-10-07a],
which feels quite relevant to the mindset of the author and how he
frames his role among the ideas in the book. The book builds a well-intentioned and complex (if not
overwrought) theory of how the universe works. And it is massive -- both
the book and theory.  It goes from the subatomic to the cosmos and God.
At various points, he's been known to followers as a mystic of sorts,
and you [could be forgiven for thinking][2019-10-07c] he aspires for
that, judging by the ways he presents and centers himself.

   [2019-10-07a]: https://www.google.com/search?q=brief+history+of+everything&tbm=isch
   [2019-10-07c]: https://www.youtube.com/watch?v=BA8tDzK_kPI

The book has terms and language for everything. It's over
500 pages. It's formatted ostensibly as a conversation between two
people (a Socratic dialogue), but it is in reality just Ken Wilber
spending 500 pages explaining his theory. It's an explanation
masquerading as a conversation. I don't think he mentions another person
through the whole book. But while you might guess that I don't like the
tactics, the things he has under his microscope seem to ring true, just as do the
ideas that AMB is dancing with.

And there's perhaps another layer of comparison within these books. AMB
gives huge amounts of credit to the wonderful sci-fi author Octavia
Butler. She speaks of her as a figure of reverence, though Octavia herself
didn't aspire for that. Adrienne relates much of her own wisdom through
a lens of gratitude for the insight that arrived through her reading of
Butler.

Octavia Butler is an author who seemed to play around with the ideas of
God and spirituality to great effect. In _Parable of the Sower_ (which
is what I can draw from, as the book I've read), she seemed to explore religion and God
through a very feminine and relational lens. It's like she navigated
into the realm of the spiritual, took it apart, and reassembled the very
nature of the spiritual, into a book. And the fabric of the book itself
shared the dissassembled pieces of spirituality with the reader. I
almost imagine it like she spent time to truly understand the spiritual,
and then distributed that understanding to everyone.

Contrast that to another literary figure who spent time exploring the
realm of the spiritual and religious: L. Ron Hubbard. You may know him
as the creator of Scientology, a terribly hierarchical and oppressive
religion [built by a sci-fi author][2019-10-07b] after he was done
critiquing and writing sci-fi about it. Hubbard took the exact opposite approach
to Octavia Butler. While she took it apart and shared it, he saw the
power of the spiritual, and (after scorning it) then took control of it and concentrated it in
a form that benefitted him. He created a system in which he could be
the broker and intermediary of the power that he came to understand. He
took it apart, and reassembled it into a gun, and he put it in his
drawer.

   [2019-10-07b]: https://tonyortega.org/2018/02/03/what-l-ron-hubbard-said-about-religion-before-scientology-became-a-church/

I don't yet know what to think about these observations, but it feels
like there's something underpinning it that I'm eager to be attentive
to.

{% include title.html name="2019-10-05" %}

(Related to some previous thoughts on [consciousness being a process of
synchrony-seeking](#2019-05-12), and maybe
[language-as-organism](#2019-07-13). This [article on
laughter][laughter] is probably also good context for these thoughts.)

   [laughter]: https://slate.com/culture/2014/03/why-do-humans-laugh-the-evolutionary-biology-of-laughter.html

_**Gratitude:** I want to express attribution to SG, a new acquaintance
who I met at a loud dinner. Last night, he indulged me with his
attention and helped me speak aloud some related thoughts, which
directly re-energized me to write a bit more about this stuff swimming
around my head lately._

I recall from my undergrad that laughter is a bit of an interesting
phenomenon. It's not really about "funny" things, than it is about
communicating "hey, there's some novelty happening here!". You could
almost imagine it as a little burst of noise we send out, like crows
cawing, when we've found a new or interesting puzzle and contradiction,
and a safe space to explore it.

How this theory came about is interesting, and essentially rooted in
discovering two forms of muscles controlling our facial expressions of
laughter, signifying a two-step emergence of different forms of
laughter.

1. Duchenne laughter. Came first. Triggered by something funny. Breathy
   panting. Likely appeared before the emergence of language. From the
   [above article][laughter], it was a "signal that things at the moment
   were OK, that danger was low and basic needs were met, and now was as
   good a time as any to explore, to play, to socialize." It said, "this
   is an _opportunity for learning_".
   
2. Non-Duchenne laughter. Came second with language.  "As people
   developed cognitively and behaviorally, they learned to mimic the
   spontaneous behavior of laughter to take advantage of its effects."
   But there are subtle "tells" where the eye muscle movements don't
   always come with this version.

So through this particular lens (which may not be the full story, mind
you), laughter is  maybe more like a very primitive, pre-linguistic form
of communication that we evolved and repeatedly repurposed to our
evolving and increasingly social context. It's been repurposed into
other things. But it's really like an animal sound. It's like our "moo".

But importantly our "moo" has been put partially under our cognitive
control. And over the course of human social development, we learned to
"deploy" our "moo" in a calculated way to better shape our desired
social situations, to manipulate our social context based on our desires
(e.g., our cultural software), and not just our hardware instincts.

So maybe it's more like we evolved to wire our animal sound of laughter
to our software level, rather than only our hardware level (the latter
of which is like "moos" and "caws").

But further, I'm curious whether there's also another layer that's
interesting. If you were to take for granted that ["seeking and
generating synchrony"](#2019-05-12) in the minds of others is something we're maybe
programmed to do as conscious creatures. I imagine it a bit like our subconscious drives are
seeking others who will join us in building a meme-based force of united
will. Which kinda makes sense if you start to think of the essence of
humanity being the langauge and concepts living in our brains -- living
within the vessel or spaceship of our biology.

And viewed that way, primitive Duchenne laughter represents a hardcoded
way for us to broadcast a _physical space_ (1) where novelty or a new or
interesting contradictory idea has been discovered, and (2) that is a
safe physical space to explore that idea, to remix it not just within a
single mind, but in the shared capacity of a group of minds. It's a safe
space to form [a megazord][megazord]<sup>1</sup> of minds to work
together to share some ideas in a space that has been flagged as full of
ideas.

   [megazord]: https://powerrangers.fandom.com/wiki/Megazord

This feels like it explains a lot of our experience of laughter -- our
draw to be near it, to move toward it, to participate in it. That would
satisfy all the needs of a purported language organism that lives within
our minds.

Oh god, this langauge-as-organism thing is a deep rabbit-hole, and it
strikes me as either 100% real and informative of the world, or totally
insane :)

<sup>h/t [CoTech co-op community](https://community.coops.tech) for
[inspiring](https://outlandish.com/blog/the-cooperative-technologists-have-landed/)
the Megazord analogy.</sup>

{% include title.html name="2019-10-04" %}

(Building on [some previous thoughts of language as an organism](#2019-07-13).)

So if language is the organism, then what are it's lifecycles. It
perhaps becomes interesting to think of language or all sorts as
"living", even when it's written on a wall. Perhaps it's best conceived
of as a dormat stage of the language organism.

So when words are written on the east wall, and words are written on the
west wall, they are dormat. They are concepts and ideas that cannot
combine and remix. These ideas cannot fuck. They can't generate new
ideas together, with pieces of one and pieces of another married and
intertwined.

But a-ha! So here comes the human mind: the fertile replication machines
of the system. It can consume and take in the dormant form of the
language organism on the east wall, and the dormant form on the west,
and it can bring it into a shared space that recombines and remixes, and
finds the best parts of each to shape together and act.

So perhaps the human mind is better conceived as the biological
replication machinery of the language organism -- the mind is the
fertile environment of recombination, not unlike DNA polymerase is the
replication machinery of the cellular environment, or the _cellular_
milieu. And so our minds are like the piece of the giant system moving
through the _terrestial_ milieu -- through the thin skin of matter than
wraps the earth and drifts with purpose within the viscosity of the
atmosphere.

{% include title.html name="2019-10-01" %}

Was listening to a [wonderful Upstream podcast episode][upstream-lisi]
in which Lisi Krall was interviewed. She is just bursting with
provocative ideas on ecologies, language, entymology, and the emergence of
agriculture. But the ferocity on which she advocates for the importance
of the last one really struck me.

   [upstream-lisi]: https://soundcloud.com/upstreampodcast/lisi-krall

It inspired me to get into my usual _[complexity
science][complexity-note]_ way of thinking: What might this event
represent as a selected adaptation in the network at one level (human
society), and how might it be generalized to events that have happened
at other levels (biological)?

   [complexity-note]: #2019-05-17

Perhaps you have heard of mitochondria. If you remember from high
school, mitochondria are the "power plants of the cells". They produce
all the energy that runs the damn show. All complex multicellular
organisms have mitochondria. It's a way-old adaptation.

But there's a funny thing about how mitochondria came to be hanging out
in our cells, making us the energy we need as complex lifeforms. You
see, they have their own DNA, separate from ours. And the reason they
have that, is thought to be because they [used to be a separate
organism][mito-origin]. But somewhere along the line, way back when, a
mitochondria was enveloped by another, larger cell. And the mitochondria
was like "hey, I like these new digs", and the host cell either didn't
resist, or maybe it's little parasite allowed it to do more than it
could before, and fare better in the environment than non-parasitized
cells without mitochondria.

   [mito-origin]: https://en.wikipedia.org/wiki/Mitochondrion#Origin_and_evolution

But anyhow, these two primitive creatures stumbled into destinies that
became intertwined. They learned to reproduce together, with the
mitochondria never leaving the host.

In some sense, the host cell simply adopted another organism, and
started nurturing it to produce energy for itself. Or maybe it was that
the parasite found a host that would protect it and allow it to
reproduce more than it ever could have on its own. Really both are true,
depending on your frame.

But anyhow, maybe you see where this is going. Perhaps agriculture is to
the human society's evolution, what mitochondria are to the evolution
from prokarytic to eukaryotic life. Each event was a symbiotic
envelopment of life-forms into the domain and jurisdiction of another.

Each allowed the host to re-organize information storage/exchange
systems it already had, and achieve new scales:

1. the mitochondrial revolution allowed cells, which already used DNA, to
   use that DNA in new ways; to begin driving processes that were
   previously energetically infeasible.

2. the agricultural revolution allowed humans, which already used
   language, to use that language in new ways; to begin driving
   processes that were previously energetically infeasible.

But this begs the question: Is the new order brought on by the
revolution itself, or does that simply unlock latent capacity in the
information system that was already there?

{% include title.html name="2019-09-30" %}

Was thinking about my cousins, and how I don't get to see them and their
kids as much as I'd like. And it got me thinking toward the trade-offs
we make in deciding between pursuing the raising of children vs the
raising of other pursuits in the world.

Thinking about the careful work of keeping a foot in both worlds --
being in touch with adults raising kids, in touch with the kids
themselves, and in touch with adults raising ideas. It got me thinking
that to be amongst adults raising ideas, these folks perhaps surround
themselves in the sorts of memes that can only nourish a small group of
people like them. Academics being the deepest example of this, toiling
away on perhaps important concepts that are utterly inaccessible to most
minds on earth. But at best, a people raising ideas figure out how to
help those ideas nourish other adults; how to feed them carefully into
the existing minds and cultures that are already living and breathing in
the world.

But that same creative space and process perhaps represents a milieu
that offers no nourishment to a child's mind. A kid won't care what
great meta concept or world-bending or society-improving thing their
parent is doing. If they experience that as a poverty of attention and
information that is accessible to them -- here and now in the mental
space in which they exist -- then that's a failure as a parent.  That
child might have a harder time growing into space of abundance that
allows them to appreciate what the parent is working on. Or they'll
arrive there with their own baggage and disadvantage.

Anyway, I suppose my realization is that raising kids is its own
informational niche; almost like an ecological niche. The mind of the
adult and mind of the child are not nourished on the same informational
diet. And it's a place of compromise.

Adults sometimes choose not to straddle the niche of raising children
and raising ideas, instead working only on ideas. But these adults
sacrifice an important negotiation and compromise that is perhaps part
of our deep history. And perhaps this negotiation is very intertwined
with what it is to be human. And I wonder if adults who neglect this
phase of development (child-rearing), might end up living down a strange
path of development, where their minds take a different form than our
ancient genes are equipped to successfully navigate.

{% include title.html name="2019-09-29" %}

Last fall, I was lucky enough to get the opportunity to do a
participatory research fellowship in Taiwan, writing a report about the
origins of an incredibly inspiring civic hacker commmunity/network
called g0v (pronounced _gov-zero_). In the time since, I've been
struggling to piece together a difficult narrative and theory that my
time there helped me to start seeing the contours of.

I'm a bit intimidated by how sweeping a hypothesis it feels like I'm
leaning toward. Others have expressed that one should be skeptical of such
things, and I tend to agree. But despite that wariness, I keep fitting
pieces together, wiggling them around, stepping back every so often, but
continuing to walk to other sides of the same table.

Some of my hesitancy is that I want to take the time to get my
attributions correct. It feel very important to both my own sensibility
(and the substance of the evolving hypothesis) that I tread careful with
the knowledge I'm claiming to be seeing, and I'd like to embody theories
of _[feminist citation][]_ (h/t DCW) as much as possible as I nurture
these ideas amongst others and amongst aspects of myself.  Which is to
say, I want to attribute as much as possible, not in the spirit of
solidifying my authority as a speaker, but in calling attention to all
those I've learned from, and ensuring that they derive
benefit/credit/power/recognition through their experiences and insights
moving through me as conduit.

   [feminist citation]: https://cmagazine.com/issues/126/feminist-approaches-to-citation

I have a sense that this work might be the culmination of the last few
years of tenuous employment and exploration. I feel uniquely privileged
to feel some of these connections between topic areas -- as a community
organizer, technologist, and biochemist with an interest in network
science and systems, but also deeply grounded in human-scale concerns
like empathy and interdependance (h/t AMB). And it feels like it doesn't
hurt to have a skepticism of overly hierarchical systems and
authority-based leadership (which often minimize relational leadership).

The development and explanation of the theory might have to move at a
slower pace, but I just wanted to bookmark the scope as a list of
topics I'll be trying to synthesize from:
biology,
evolutionary genetics,
[group selection](https://en.wikipedia.org/wiki/Group_selection),
[evolution of sexual reproduction](https://en.wikipedia.org/wiki/Evolution_of_sexual_reproduction),
networks and social science,
[structural holes](https://en.wikipedia.org/wiki/Structural_holes),
[social physics](https://www.penguinrandomhouse.com/books/314230/social-physics-by-alex-pentland/9780143126331/),
mathematical properties of [small-world networks](https://en.wikipedia.org/wiki/Small-world_experiment),
the [small world effect](https://en.wikipedia.org/wiki/Small-world_experiment),
Hofstede's [cultural dimensions theory](https://en.wikipedia.org/wiki/Hofstede%27s_cultural_dimensions_theory) (of leadership),
philosophy of open source,
[emergent strategy](https://www.akpress.org/emergentstrategy.html),
gendered approaches to organizing social networks,
the [gendered nature of social capital](https://journals.sagepub.com/doi/10.1177/104346398010001001) in networks,
the [Leiden theory of language evolution](#2019-07-13),
and [complexity science](https://en.wikipedia.org/wiki/Complexity_theory) (h/t AMB and Santa Fe Institute).

If I were to try to summarize my highest hope: It's about pulling
together the foundations of **a network-centric and mathematical basis
for feminist ideals**, which speaks the abstract language of the
dominant neurotype in tech, a sector that is madly building the digital
underpinnings of a world, and building it not only blindly, but badly.

Disclaimer: I've been saying for a few years that I'm in search of a
personal (and collective) spiritual foundation that _maps to
base-reality_. Which is to say, a belief system (perhaps simple in
practice) that is underpinned by forces that hold true down to the
lowest levels of reality. So I'm inclined to seek patterns that might
suggest that sort of thing at work :)

{% include title.html name="2019-07-13" %}

Inspired by sci-fi author Charlie Stross' [musing on "slow
AI"](https://boingboing.net/2017/12/29/llcs-are-slow-ais.html), I often
think about the ways that we might be in the midst of slow singularities
at different levels of [the
stack](https://mitpress.mit.edu/books/stack). And lately, I've been
rolling around an idea about why the conscious experience of being human
seems to be so hard to pin down. We talk a lot about how the complexity
of human _culture_ is what separates us from other creatures. But what
does that mean? How can we dissect that and look at it like an alien
might look at it.

And I wonder if we'd do better to understand our experience of being
human as what it's like to be a **cyborg -- we're an organism made of
partially biological and partially linguistic structures.** What if we
should think of language more like a separate living creature that has
grown in the fertile environment of our nervous systems.  What if we
could look at human culture through a much more alien lens. Maybe we
could just as easily imagine human culture as language (the creature)
_terraforming our biology_ as it's living symbiotically within our
minds. And not only our own biology, but also the ecologies and lower
levels in which we exist. And in this way, it's making a place in which
it may flourish -- our cities, our conversion of biological and mineral
resources, etc.

And if this is the case, we can perhaps imagine our current scenario in
a different light. We are maybe on this course where our collective culture
is taking us to the edge of a precipice. We are essentially converting
the systems on which we depend into fuel for this cultural beast which
seems unable to reckon with the reality that it's dissembling the platform on which
it stands. And this reminds me a little bit of a variation of the
[paperclip maximizer thought
experiment](https://wiki.lesswrong.com/wiki/Paperclip_maximizer). In
that version, a poorly calibrated artifical intelligence, in
single-minded pursuit of its goals, might convert all available matter
into _computronium_, or programmable matter used for achieving more
computation.

Maybe we're living through a slow singularity. Maybe we _are_ the slow
singularity. A biological-memetic singularity. In the same way that you
tell someone: "You're not stuck in the traffic jam; you _are_ the
traffic jam." In this imagining, the memetic creatures of language
(which are half of what we are, in a way we perhaps find hard to
separate), are dissembling and destabilizing the biological and
ecological systems on which they stand, converting all matter to serve
the goals of the creatures living in the minds of a single biological
host.

It almost sounds like to plot of a sci-fi space opera, but maybe that's
what we're participating in. We just can't see how alien we are. But
maybe to the rest of the creatures on this earth, we look like some
equivalent of unknowable cyborg, operating based on principles and
drives and motivations that they cannot experience or understand or keep
up with.

(After starting to [amateurly work through the concepts around this
idea][leiden-tweet], I came across a niche branche of linguistic called
[the Leiden theory of language][leiden-theory], that has a ton in
common. Also, my language likely started to mix with their, and so I am
indebted to their years of thoughtful work and rigorous academic
pursuit.)

   [leiden-tweet]: https://twitter.com/patconnolly/status/1140858760484786178
   [leiden-theory]: https://www.researchgate.net/publication/316659561_The_language_organism_The_Leiden_theory_of_language_evolution

{% include title.html name="2019-06-13" %}
Working in a high-churn culture like a civic hacknight, where 40% of
people might be new each week, there are some interesting opportunities
to work on non-exclusive and unloaded language for being critical of
dominant systems. Here are some turns of phrase I've discovered to be
useful:

- Instead of speaking against capitalism, speak of **capitalism's lack
  of curiosity** toward certain important things. I often say "I try to
  work on things that capitalism isn't curious about." People embedded
  in capitalist systems find it hard to be critical of it, likely
  because it's hard to imagine or hope  for anything else. But it's easy
  to agree that capitalism does not display an interest in certain
  things that humans are interested in. And a very human frame for that
  is _curiosity_. Being anti-capitalist is a heavy title to wear, but
  being skeptical of _incurious systems_ is easy. We can talk about it
  just as we might speak of skepticism toward intellectually or
  emotionally incurious people who don't ask questions of peers.
- Instead of speaking only about "diversity & inclusion", speak
  sometimes about **generosity of leadership**. I like to think of this
  as creating a positive pressure for leadership, so that it will flow
  outward. It doesn't prescribe where that leadership should flow, but
  if the general environment encourages thoughtfulness around
  representation, then the folks sharing leadership will inevitable end
  up on their own personal journey of who they should offer that
  leadership to. This allows the work to happen more in the headspace of
  the person doing the work.  They will have more ownership of the
  conclusions drawn.  Combined with short rotations of leadership,
  there's many surfaces and transition points to learn from. Community
  projects aren't companies -- you can only once appoint founders, so
  that decision bears great importance, but if the person stewarding an
  initiative changes often, then each change is an opportunity for each
  group to recalibrate on who that culture values seeing in a leadership
  position.
{% include title.html name="2019-05-18" %}
The [complexity video][complexity-vid-ants] that I linked yesterday
talked about the steps that ants follow to make decisions on placing a
new nest: info-gathering, evaluation, deliberation, consensus-building,
choice, implementation.

   [complexity-vid-ants]: https://www.youtube.com/watch?v=IEEBOrpDIow#t=7m20s

Curious whether there are analogies to how people engage in
individual-to-individual collaborations (person offering support to
person), but also more complex collabs. As in, up through more advanced
forms like individual-to-group (person offering support to other group),
or even group-to-group collabs (group offering support to another
group).  This last one is understandably the most complicated way to
work together, because knowing self and other as a group is so much
harder and less intuitive for our individual sensibilities to navigate.

{% include title.html name="2019-05-17" %}
I'm inclined to see the world through a lens of [complexity
science][complexity-video], where high-level patterns at one scale
(e.g., cell death in biological systems) can perhaps teach us things
about patterns that will fare best at other scales (e.g., governance
systems in society).

   [complexity-video]: https://www.youtube.com/watch?v=IEEBOrpDIow#t=0m44s

I've been slightly disconcerted by the fact that centralization seems to
"win" in most every biological system -- most every creature that gets
to a certain level of complexity, also develops central nervous systems.
The skin cell of the finger becomes subservient to the brain cell.  What
might this say about authorianism vs democracy?

The optimist in me wants to believe that maybe, if the universe favours
centralization, then maybe this could be the force that humanity rallies
against. Because we're good at raging against things. It seems to be
part of how humans operate, and work together. And so we often rage
against one another. But maybe, we could create a shared understanding
that the very fabric and tendencies of the _universe_ are conspiring
against some shared democratic ideals. And so then we could just rage
against that non-human enemy, the entropic laws of the universe itself.
What a perpetual underdog story that would be. It could perhaps occupy
our attention and energy for a long time.

But anyhow, today, I realized a bit of a catch in some of my thinking. I
often look at the patterns in the world around me, and try to learn from
them. So I'd look at how brains (one example of a network highly
saturated in activity) seem to have evolved a need for sleep, a period
of rest. And then I might wonder what that might teach us about how our
comtemporary society (another network of nodes that is increasingly
saturated with signal) might be begging for similar interventions --
periods of rest from the high activity, for re-organization.

Or I might look at how we see the relationship between structure and
anarchy in living symbiotic systems that are animal bodies -- the
hierarchy of the traditionally conceived "host" animal, and the anarchic
gut biome that plays such an important role in processing raw components
from the wider world. What might that teach us about the role of chaotic
spaces adjacent to government? (Hat-tip to MH for a conversation that
sparked those particular thoughts.)

I believe that these comparisons aren't simply _analogy_, but rather,
they're examples of multiple systems converging on similar outcomes due
to the shared properties of networks more generally. Each network
operates and is built from different substrates, different components,
but there are common underlying dynamics at play. This is what I
understand from complexity science.

And this is particularly important in our current situation. We are now
running network experiments on global scales. We don't necessarily have,
in our systems, the capacity to run a million iterations of the system.
Ecosystems could run millions of cycles among populations of
individuals. Bacterial biomes could run many cycles. Some parts of human
culture have had the space to run a scant few experiments, as cultures
rise and fall. But we're getting to a place we _must_ learn from other
layers of the network, because we don't have space or time to run the
experiments to completion at the scale we've arrived, at the global
scale.

But anyhow, it occured to me today that perhaps there's something I
should be wary of while looking to learn from the patterns that have
"won" at lower levels. Because those patterns are often ones that
emerged in networks where hierarchy prevailed. So I should be cautious
not to look _too much_ to them for my learning. Because perhaps some of
them are patterns of _appeasement_ to hierarchy. Perhaps some of them
represent ways to survive in the cracks between towering structures of
central control, rather than an imagining of what might be possible if
we exercised human-scale democratic values at our level.

{% include title.html name="2019-05-16" %}
(Thinking [back](#2019-05-12-a) on the intuitions involved in our
conscious experiences) Maybe the evolved trait that is consciousness, is
more about how we feel the sensation of the ride. Like a surfer's
developed instincts, honed for riding waves. We can carve that wave, and
enjoy the simple thrill of navigating it, but the major aspects of the
experience -- the orientation, the shore as ultimate destination -- is a
force beyond our control.

{% include title.html name="2019-05-15" %}
(Building on [a prior thought](#2019-05-12-b) about what underlying process might be
getting hijacked in the "bad" scenarios of "fast" and "slow" AI, ie. conventional general
AI and corporations, respectively.)

So what if "synchrony" is the thing that all our human intuitions have
evolved to select for. Our [laughter](#2019-10-05), our sense of belonging, our falling
in love, our enjoyment of engaged conversations. Perhaps these all
increase the synchrony of our collective endeavour of humanity. And in
that, a process of converting an "other" into a "self" -- something that
lights up our mirror neurons, like watching a sports team (_your_ sports
team) working together on the other side of the airwaves, or speaking
across the couch to a lover, or even across the corpus callosum to a
self that's lucky enough to already be in agreement.

We subjectively feel these human experiences as something more, but
perhaps the universe fundamentally _understands_ them only as a
collective of matter, increasing synchrony with itself.

Ok, so if this is true, then what are the dangers? How can these
intuitions that largely serve us well, that help us to create synchrony
with our fellow human actors -- how can this be hijacked?

I'm starting to wonder if that is what feels do dangerous about
corporations. These are deeply inhumane creatures, operating largely
with very different motives. Yes, we've encoded these motives in laws at
our scale. But what emerges is perhaps above us. We have allowed these
things to optimize according to rules that, if operating at a human
level, would be undestood as psychopathic and anti-human: Pure profit
maximization is condoned.

And that's nothing new, but what is alarming is how these things can
start to run with a life of their own, and seem to use humans as
"peripherals" of sorts. They _deploy_ people with certain skills and
motivations that are perhaps altogether human and sincere. I sometimes
imagine employees as some sort of sci-fi puppet on a stick, being thrust
into our realm. These people are given autonomy, and they often act in
good faith, but they are selected by the larger aparatus for this
sincerity in which they operate. Their very authentic interactions can
run cover for the very inauthentic mechanisms at the core of
corporations -- the profit maximization.

And back to synchrony. What I worry here is that the corporation has a
very different synchrony that it is propogating in the world. It has its
own patterns and logic, and they are not ours. They're building something
else. But when persons representing these larger interested interact
with people, they _feel_ like they're increasing the synchrony of human
processes. They feel like they're pursuing very human goals, down in the
trenches with us. All the participants experiences and intuitions might
even be telling them "YES, we're doing something pro-human. We're
becoming more aligned. We're becoming in sync." But on the backend,
where the power is, there's another order building.

It's perhaps a little like how we imagine "fast" AI might go awry. If we
were to meet one, we might feel it's connecting with us on the front
end. Its brows might furrow in the way that make us feel understood. It
might respond in a way that we understand to mean it's _feeling_ for us,
becoming aligned with us. But these are just the movements of servos and
the motions of human projection. The servos are not evil -- they are not
good or bad. They are peripherals. They are serving something behind
them.

The octopus is an interesting creature. It has a distributed brain that
extends into its arms. It's central brain gives loose orders, but the
limbs actually do some of the work of knowing what to do. It seems to be
a common curiosity, to wonder aloud how alien an octopus consciousness
might be. But perhaps we already know. Perhaps we're living in a system
not unlike the octopus'.  We are appendages of things above us -- we
process, and integrate, and make decisions. Maybe we can't know what
it's like to be the octopus, but maybe our navigation of the corporate
entities of capitalism tells us a little about what it's like to be the
octopus' arms.

{% include title.html name="2019-05-12" %}
In conversation with my friend SL ages ago, had chance to work through a
thought that maybe society is like a board of flickering, disjointed
blinky lights, each representing a conscious creature. The acts that
we're engaged in are at their core an act of creating synchrony in that
blinking, and holding it as long as possible. So while the board is a
proxy, with just one dimension (brightness), we are navigating
uncountable other dimensions of potential synchrony. Many of these
dimensions are antagonistic. There are countless ways to resolve these
systems of equations.

I feel this view is informed by a TED talk I once watched, [Do we see
reality as it is?](https://www.youtube.com/watch?v=oYp5XuGYqqY). The
speaker openned with a story about a beetle that knew to recognize a
shape as a mate. That simplified assumption for how to move in the
world, it held true for a long time. Until an Australian beer company
created a bottle that tricked that beetle's intuitions. Instead of
finding mates, it began choosing the dead-end option of fucking the
bottle. And it started to go extinct. Its intuitions, which used to
serve it well, were now being hijacked as the environment changed. And
while this instance was a change outside its control, humans could
theoretically do the same thing within their own environments, sending
themselves on a more complex dead-end trajectory.

But I'm curious what underlying process is being hijacked. For both the
beetle and for us. What common process is being navigated, that our
intuitions are highly tuned to optimize for, but that is being thrown
out of whack. And I wonder if it's sychrony itself. I find this
supported by recent research that shows that deep conversation
(presumably creating a subjective sense of reward in participants)
results in [sychrony of brain activity under MRI scans][hyperscan].

   [hyperscan]: https://www.scientificamerican.com/article/hyperscans-show-how-brains-sync-as-people-interact/

So what if the things that we're moving toward as conscious life (of
which "intelligent life" is just a specific subset) is an increase in
sychrony with our fellow travellers -- the human persons, animals, plants,
buildings, internets, and architectures of all sorts. Maybe that's the
thrust of it. A sort of cosmic like-attracts-like of consciousness.

<a name="2019-05-12-a"></a>
So if that's the case, then our experience -- the things we desire --
are just a proxy for the baser need and drive for sychrony. Our senses
and intuitions are simply the things we've evolved to root out that
synchrony. Just like the beetle evolved this attraction to recognize a
thing like itself, which implies an underlying synchrony of information
and simple concepts within its mind.  Perhaps evolved language itself is
just our way of seeing other deeper, more nuanced synchrony within the
minds of other beings like ourselves.

<a name="2019-05-12-b"></a>
And these thoughts lead me to the worries. What might we be engaging in
that's like the beetle? What bottle are we fucking? What things are we
pursuing away from life, with miscalibrated sensors, seeking sychrony
and finding only hollow vessels? I'm still working through this, but I
suspect there's something to be learned about how we can navigate our
future "fast AIs" and [our contemporary "slow AIs", the corporate
structures][slow-ai] we find ourselves navigating amongst as fellow
travellers.

   [slow-ai]: http://www.antipope.org/charlie/blog-static/2018/01/dude-you-broke-the-future.html

{% include title.html name="2019-04-11" %}
Thinking about speculative civic sci-fi related to smart cities.
Wondering if maybe human culture is best thought of as a probability
cloud, not a state machine. Just as the lightbulb was invented in
several different places near the same time, a specific arriving of a
future is not a singular event, but an potentially inevitable field of
moments evoked. And if this consideration of society as a probabibility
space is correct, then it's less of question of _are_ these people doing
this good thing or this bad thing, but _can_ they. If they _can_ do the
bad thing, then that future is more adjacent.

Or considering through a social physics lens. Through that lens, we think about
possibilities through how many hops away an idea is between people.
Maybe we can consider the world we want by how many hops away it might
be -- good or bad -- from a desireable or undesirable possible reality.

Metaphor: We're perhaps moving through the part of the marble tilt maze where
the holes run thick and the steel ball drifts lazily across narrow
surfaces in parabolic arcs.

{% include title.html name="2019-02-16" %}
(Thinking on "Brief History or Everything") Considering emergence and
"holons", that which are both wholes and parts.  Maybe commons-based
peer production is favoured because it involves small pieces that can be
shuffled and _restacked_ in search of emergent properties.

We are matter that encodes descriptions of itself. We rattle the air
between us. We are ball lightning.

{% include title.html name="2019-02-01" %}
How might super-intelligent descendants of cold-blooded lizards think of
or describe _windchill_? Compared to us, it'd be so much more dangerous--a
killer. How would their culture understand it, and talk about it?

{% include title.html name="2016-07-26" %}
I want to build a "crazy" that's so comprehensive that other people can live in it.
